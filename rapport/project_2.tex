\documentclass[a4paper,12pt]{article}
\usepackage{srcltx}
\usepackage[english,swedish]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{parskip}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{algorithmic}


\makeatletter
\def\imod#1{\allowbreak\mkern10mu({\operator@font mod}\,\,#1)}
\makeatother

\renewcommand{\O}{\ensuremath{\mathcal{O}}}
\renewcommand{\*}{\ensuremath{\cdot}}

\begin{document}

\selectlanguage{english}
\title{DD2440 Advanced Algorithms (fall 2009) \\ Project 2 -- Integer
factorization}
\author{Joel Pettersson \\ 880519-0637 \\ joelpet@kth.se \and Linus Wallgren \\
880213-0099  \\ linuswa@kth.se}
\date{\today}
\maketitle
\thispagestyle{empty}
\newpage
\setcounter{page}{1}

\selectlanguage{swedish}

\section{Inledning}

\subsection{Problembeskrivning}

Ett primtal är ett tal som endast är delbart med ett och sig själv. Alla tal som
inte är primtal går att dela upp i primtalsfaktorer. Det vi söker är varje sådan
primtalsfaktor till ett visst heltal, hädanefter refererat till som $n$ om inget
annat anges.




\section{Metod}

\subsection{Trial division}

Det mest triviala sättet att angripa problemet på är att bara testa om talet $n$ är delbart med en primtalsfaktor. Det är ett effektivt sätt att få bort små faktorer men det skalar inte speciellt bra då primtalsfaktorerna blir mer och mer sällsynta ju större faktorer vi söker.

I och med att algoritmen är såpass simpel finns det inte jättemycket att optimera. Det enda man kan hålla koll på är så man inte tittar på eventuella primtalsfaktorer större $\sqrt{n}$. Om vi låter talet $n$ beskrivas av två faktorer, $p$ och $q$, får vi $n = pq$. Ju större q är, desto mindre blir p och vice versa. Om fallet är att p är större än $\sqrt{n}$, kommer p vara mindre än $\sqrt{n}$, den största faktorn vi kan få blir således $\sqrt{n}$. 

\subsection{Pollards rho}

Vi betecknar den största gemensamma nämnaren med funktionen $gcd(x,y)$
\subsubsection{Grundläggande teori}

Låt $n = pq$, där $p$ och $q$ är okända faktorer till $n$. 
Vi söker då två tal, $a$ och $b$, sådana att $a = b (mod p)$.

$a=b(mod p)$

$a-b = 0 mod p$

$a - b = k*p$

Vi ser att $|a-b|$ är en multipel av $p$, även $n$ är en multipel av $p$ eftersom $p$ är en faktor till $n$. Den största gemensamma nämnaren mellan $|a-b|$ och $n$ är således en faktor till $n$, nämligen $p$. 

I dess grundläggande form utnytjar Pollards rho Floyds cykel-finnar-algoritm. Den går ut på att hålla koll på två tal som rör sig i olika hastighet i en cykel. När talen är lika har vi gått ett varv i cykeln.

Vi kommer leta därför att efter tal $a$ och $b$ sådana att $gcd(|a-b|, n) \notin {1, n}$. Om $gcd(|a-b|, n)$ visar sig vara 1 fortsätter vi leta med nya $a$ och $b$, ifall $gcd(|a-b|, n) = n$ innebär det att $a=b$ vilket, enligt Floyds cykel-finnar-algoritm, betyder att vi har fullföljt vår cykel och inte kommer hitta någon faktor.

Vi genererar de båda talen $a$ och $b$ med hjälp av en pseudo-slumpmässig funktion modulu $n$. Vi kallar denna funktion $f(x)$.

Anledningen till att vi kan applicera en Cykel-finnar algoritm är att vår pseudo-slumpmässiga funktion ger oss ett tal modulu N vilket innebär att vi endast kan få ett ändligt antal värden. Vi $a=f(a)$ och $b=f(f(b))$ i varje ny iteration av algoritmen. Vi gör detta för att hålla koll så att vi inte beräknar samma tal flera gånger, för när $a=b$ innebär det att vi gått ett varv i vår cykel och kommer således att börja om om vi skulle valt att fortsätta.

\subsubsection{Algoritmen}
Vi väljer funktionen $f(x) = x^2 + d (mod n)$ för att den visat sig vara effektiv vid experiment, mer specifikt är $d=1$ mycket effektiv. Det är viktigt att $d \notin {0, -2}$ då det innebär att vi  fastnar i en loop som aldrig kommer ge oss någon nyttig information. Vi börjar med ett slumpmässigt startvärde $X_0$ och sätter $a=b=X_0$. För varje iteration av algoritmen gör vi följande:

$a = f(a)$
$b = f(f(b))$

$b$ kommer alltså röra sig dubbelt så fort som $a$, vilket är nödvändigt för Floyds cykel-finnar algoritm.

För varje itteration beräknar vi också den största gemensamma delaren mellan $|a-b|$ och $n$. Om resultatet är $1$ har vi inte hittat någonting och gör ytterligare en itteration. Om resultatet blir $n$ innebär det att $a=b$ vilket betyder att vi inte kunde hitta någon faktor. I annat fall har vi hittat en faktor. Vi kan nu fortsätta genom att applicera pollards på de två faktorerna återstående faktorerna, tills vi finner primtal.

\begin{algorithmic}
    \STATE pollards rho($n$, $X_0$)
        \STATE $a \gets X_0 $
        \STATE $b \gets X_0 $

        \WHILE{$ factor = 1$}
            \STATE $a \gets f(a)$
            \STATE $b \gets f(f(b))$
            \STATE $factor \gets gcd(|a-b|, n)$
        \ENDWHILE

        \IF{$factor = n$}
            \STATE \COMMENT{Vi kunde inte hitta någon faktor}
            \RETURN $-1$ 
        \ELSIF{$factor > 1$}
            \RETURN $factor$
        \ENDIF
\end{algorithmic}


\subsubsection{Optimeringar}
\paragraph{Nya startväden}

Ifall $gcd(|a-b|, n) = n$ kan vi istället för att ge upp försöka med ett nytt startvärde, på det viset kan vi faktorisera mer eller mindre alla tal med hjälp av pollards $\rho$.

\begin{algorithmic}
    \STATE pollards rho($n$, $X_0$)
        \STATE $a \gets X_0 $
        \STATE $b \gets X_0 $

        \WHILE{$ factor = 1$}
            \STATE $a \gets f(a)$
            \STATE $b \gets f(f(b))$
            \STATE $factor \gets gcd(|a-b|, n)$
        \ENDWHILE

        \IF{$factor = n$}
            \STATE \COMMENT {Vi testar ett nytt startvärde}
            \RETURN pollards rho($n$, $X_0+1$) 
        \ELSIF{$factor > 1$}
            \RETURN $factor$
        \ENDIF
\end{algorithmic}

\paragraph{Flera gcds samtidigt}

Vi observerar att om den $gcd(x, y) > 1$, så är även $gcd(x\cdot k, b)>1$ för alla heltal $k$. Detta följer naturligt av definitionen på största gemensamma nämnaren.

Genom att utnytja detta fenomen kan vi räkna ut flera $|a-b|$ innan vi beräknar den största gemensamma nämnaren, vilket är en tidskrävande operation i förhållande till den tid som krävs för att applicera $f(x)$ på $a$ och $b$.

\begin{algorithmic}
    \STATE pollards rho($n$, $X_0$)
        \STATE $a \gets X_0 $
        \STATE $b \gets X_0 $

        \WHILE{$ factor = 1$}
            \FOR {$i = 0$ to $iterationer per gcd$}
                \STATE $a \gets f(a)$
                \STATE $b \gets f(f(b))$
                \STATE $factor \gets factor * |a-b|$
            \ENDFOR
            \STATE $factor \gets gcd(factor, n)$
        \ENDWHILE

        \IF{$factor = n$}
            \STATE \COMMENT {Vi testar ett nytt startvärde}
            \RETURN pollards rho($n$, $X_0+1$) 
        \ELSIF{$factor > 1$}
            \RETURN $factor$
        \ENDIF
\end{algorithmic}

\paragraph{Brent}

Tanken bakom optimeringen som Brent och Pollard kom fram till är att endast göra ett funktionsanrop till $f(x)$ i varje iteration, istället för tre. Detta sker genom att vi använder Brent's metod för att hitta cykler istället för Floyd's. 

Floyd's algoritm för att hitta cykler går ut på att låta talet $b$ röra sig dubbelt så fort som $a$. Brents algoritm söker istället efter den minsta tvåpotens som är större än längden på cykeln.
\begin{algorithmic}
    \STATE pollards rho($n$, $X_0$)
        \STATE $power \gets 1$
        \STATE $iterations \gets 1$

        \WHILE{$ factor = 1$}
            \FOR {$i = 0$ to $iterationer per gcd$}
                \IF {$power = iterations$}
                    \STATE $a \gets b$
                    \STATE $power \gets power *2$
                    \STATE $iterations \gets 0$
                \ENDIF 
                \STATE $b \gets f(b)$

                \STATE $iterations \gets iterations + 1$

                \STATE $factor \gets factor * |a-b|$
            
            \ENDFOR


            \STATE $factor = gcd(factor, n)$
        \ENDWHILE

        \IF{$factor = n$}
            \STATE \COMMENT {Vi testar ett nytt startvärde}
            \RETURN pollards rho($n$, $X_0+1$) 
        \ELSIF{$factor > 1$}
            \RETURN $factor$
        \ENDIF
\end{algorithmic}


\subsection{Kvadratiska sållet}

Den grundläggande tanken bakom kvadratiska såll-metoden är relativt enkel. Målet
är att finna två tal $x, y \in \mathbb{Z}$ sådana att
\begin{align*}
    x^2 \equiv y^2 \imod{n}, \ \text{ men } x \not\equiv \pm y \imod{n}.
\end{align*}

Då råder enligt konjugatregeln ekvivalensen
\begin{align*}
    n \mid (x^2 - y^2) \Leftrightarrow n \mid (x+y)(x-y).
\end{align*}

Vidare gäller att $n \nmid (x+y)$ och $n \nmid (x-y)$, ty $x \not\equiv \pm y
\imod{n}$. 

Därmed kommer $d = \text{gcd}\left( n, x \pm y \right)$ att vara faktorer  $n$
-- men dock eventuellt triviala sådana. Sannolikheten att vi får triviala
lösningar är $50 \%$ om $n$ består av endast två primtal och i annat fall lägre
chans. Således kan vi behöva upprepa algoritmen tills icke-triviala faktorer
hittas.

Nu återstår bara frågan \emph{hur hittar vi effektivt talen $x$ och $y$}?

\subsubsection{Fermats algoritm}

Den naiva ansatsen vore här att låta $x$ vandra från $\sqrt{n}$ och uppåt i
förhoppning om att finna ett $x$ som uppfyller just $x^2 \equiv y^2 \imod{n}$
för något $y \in \mathbb{Z}$. Detta påminner väldigt mycket om Fermats
faktoriseringsalgoritm som letar efter tal som uppfyller liknande villkor.

Problemet är att det i praktiken tar alldeles för lång tid att hitta sådana tal
på det viset, eftersom de är relativt få. Detta fick vi även bekräftat av
resultatet 2 poäng på KATTIS för vår implementation av algoritmen. En förbättrad
strategi presenterades av Dixon och beskrivs i nästa delsektion.


\subsubsection{Dixons metod}

Dixon valde att släppa på kravet på jämna kvadrater och nöjde sig med att finna
$x$ och $y$ så som beskrivet ovan fast där $y$ bara behöver kunna faktoriseras
i små primtal. Det vill säga att $y$ ska kunna skrivas som $y =
p_1^{a_1}p_2^{a_2} \cdots p_k^{a_k}$ för små primtal $p_i$, $i = 1, 2, \dots k$.

Givet en mängd sådana tal $y$ är det möjligt att genom linjär algebra, speciellt
genom Gauss-eliminering modulo 2, finna delmängder vars produkter av de ingående
elementen bildar en jämn kvadrat. Detta tack vare observationen att två tal
$y_i$ och $y_j$ (utan förlust av generalitet) kan skrivas som en jämn kvadrat om
och endast om summan av exponenterna för deras respektive primtalsfaktorer är
jämn.

Då har vi funnit ett talpar $(x, y)$ som vi sökte, vilket genom Euklides algoritm
förhoppningsvis ger icke-triviala faktorer.

Denna ansats ökar chanserna att ett sådant talpar ska dyka upp. För att
illustrera detta kan nämnas att antalet jämna kvadrater som är mindre än $84923$
är 292 stycken, medan det finns 662 stycken tal som låter sig faktoriseras av
endast 2, 3, 5 och 7 samt 4767 tal vars primtalsfaktorer alla är mindre än 30.
Ändå tar det orimligt lång tid för stora $n$ att så urskiljningslöst bara pröva
$x$. Lyckligtvis presenterade Carl Pomerance en effektiv metod för att sålla
bort ointressanta tal $x$, kallad \emph{Quadratic Sieve} (`kvadratiska sållet').


\subsubsection{Kvadratiska sållet}

Betrakta polynomet 
\begin{align*}
    f(x) = (x + \left\lfloor \sqrt{n} \right\rfloor)^2 - n
\end{align*}
och notera att
\begin{align*}
    (x + \lfloor \sqrt{n} \rfloor)^2 \equiv f(x) \imod{n}.
\end{align*}

Antag nu att vi lyckas finna heltal $x_i, i = 1, 2, \dots, k$ så att
$f(x_1)f(x_2)\cdots f(x_k)$ kan skrivas som en jämn kvadrat $y^2$ för något
heltal $y$. Låt 
\begin{align*}
    x = (x_1 + \lfloor \sqrt{n} \rfloor) (x_2 + \lfloor \sqrt{n} \rfloor)\cdots
    (x_k + \lfloor \sqrt{n} \rfloor).
\end{align*}
Då har vi en lösning till $x^2 \equiv y^2 \imod{n}$.

Om $y$ ska kunna skrivas som en kvadrat vill vi ha de ingående faktorerna
$f(x_i)$ som produkter av en gemensam uppsättning primtal, kallad
\emph{faktorbasen} för talet $n$. Av den anledningen vill vi inte ha $f(x_i)$
som delas av stora primtal eftersom det i sådana fall skulle krävas andra
$f(x_j)$ som delas av samma stora primtal. 

Så, hur ska vi bära oss åt för att välja en lämplig faktorbas?

\paragraph{Val av faktorbas}

Vi vill ha
\begin{align*}
    p_i \mid f(x)
\end{align*}
och vet att 
\begin{align*}
    &p_i \nmid n \text{ (kräver trial division med alla tal i faktorbasen före
    start) } \\
    &f(x) = (\lfloor \sqrt{n} \rfloor + x)^2 - n.
\end{align*}

Det betyder alltså att vi söker primtal $p_i$ till vår faktorbas sådana att
\begin{align*}
    (\lfloor \sqrt{n} \rfloor + x)^2 \equiv n \imod{p}.
\end{align*}
Jämför detta med definitionen för kvadratisk rest och inse att $n$ då måste vara
en kvadratisk rest modulo $p$, vilket är ekvivalent med att Legendresymbolen
\begin{align*}
    \left(\frac{n}{p}\right) = 1.
\end{align*}
Denna kan relativt enkelt beräknas, vilket öppnar för en effektiv beräkning av
faktorbasen.

Då är det äntligen dags att börja samla ihop våra $x_i$. En översiktlig
beskrivnig av hur själva sållet fungerar ges därför i nästföljande stycke.

\paragraph{Sållet}

Endast ett fåtal tal kommer faktiskt att faktoriseras fullständigt över
faktorbasen. Vi vill därför kunna sålla bort så många som möjligt med så lite
ansträngning som möjligt. Detta kan göras utifrån följande observation.

\begin{align*}
    f(x) &= \tilde{x}^2 - n, \ \tilde{x} = (\lfloor \sqrt{n} \rfloor + x) \\
    f(x+kp) &= (\tilde{x}+kp)^2-n \\
    f(x+kp) &= \tilde{x}^2 + 2\tilde{x}kp + (kp)^2 -n \\
    f(x+kp) &= f(x) + 2\tilde{x}kp + (kp)^2 \equiv f(x) \imod{p}
\end{align*}

Det vill säga, om man löser $f(x) \equiv 0 \imod{p}$ för $x_i$ får man en lång
sekvens $f(x_i)$ som är delbara med $p$. På så sätt kan vi snabbt hitta många
tal som går att faktorisera i den valda faktorbasen.

\paragraph{Gauss-eliminering}

När tillräckligt många användbara $x_i$ och $f(x_i)$ har påträffats återstår det
bara att pröva olika linjärkombinationer av dessa som ger jämna kvadrater för
produkten av $f(x_i), i \in [1,k]$. För att vara säkra på att ett linjärt
beroende existerar behöver vi samla in ett mer $x$ än antalet primtal i
faktorbasen. 

Att hitta sådana linjärkombinationer kan göras genom att bilda matrisen $A$ med
radvektorer så som exponenterna för primtalen i faktorbasen för vart och ett av
de utvalda $x_i$:na, räknat modulo 2. Uppgiften blir sedan att finna nollrummet
för $A^T$, vilket görs enklast med Gauss-eliminering.

Härifrån återstår endast att pröva de jämn-kvadrat-bildande linjärkombinationer
av $x_i$ och $y_i$ som nollrummet medger tills en icke-trivial lösning hittas
med hjälp av \emph{gcd}.

\subsubsection{Implementation}

Det var också så här långt vi hann i implementationen av kvadratiska sållet.
Dock tog det relativt lång tid att köra programmet så långt, vilket kan ha
berott på att vi inte hade implementerat någon optimering. En möjlig sådan, bara
för att nämna någon, hade till exempel kunnat vara att implementera $A$-matrisen
som rader med bitvektorer istället för vektorer med booleans. Då hade man dels
sparat en del utrymme, men framför allt hade man kunnat parallellisera
radoperationerna i Gauss-eliminationen. 




\section{Resultat}

Första versionen av Pollards, ensam, gav oss 28 poäng på kattis. Den enda
optimeringen som gjordes var att dividera på 2 om talet var jämnt.

I andra revisionen av Pollards rho ändrade vi startvärdet för de två talen till
3, vilket gav oss en extra poäng samt en hel del extra tid, men tiden över kunde
vi angripa större tal. I den här revisionen angrep Pollards rho alla tal mindre
än 87 bitar, vilket resulterade i 31 poäng.

Genom att implementera trial division på de 256 första primtalen kunde vi ta hem
ytterligare poäng, kattis gav oss vid den här tidpunkten 38 poäng.

Nästa steg var att testa med nya startvärden för de två talen i Pollards rho om
vi misslyckades att finna en faktor. Detta innebär att vår implementation av
Pollards rho lyckas faktorisera alla tal vi får från Kattis som är mindre än 87
bitar.

Genom att beräkna den största gemensamma delaren endast var 13e iteration
lyckades vi minska körtiden med mer än 10 sekunder. Detta gav oss möjligheten
att testa tal mindre än 88 bitar, vilket resulterade i 39 poäng.

Den sista optimeringen av Pollards rho vi gjorde var att byta
cykel-finnar-algoritmen från Floyds till Brents, det gav ungefär 5 sekunders
förbättring och möjligheten att angripa alla tal mindre än 89 bitar. Tråkigt nog
gav det inte oss några extra poäng så vi gick tillbaka till 88 bitar igen. Med
tiden som blev över gick vi från att testa med de 150 första primtalen till att
testa de 10000 första primtalen i trial divison, vilket gav oss den slutgiltiga
poängen, 40.







\end{document}
