\documentclass[a4paper,12pt]{article}
\usepackage{srcltx}
\usepackage[english,swedish]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{parskip}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{algorithmic}


\makeatletter
\def\imod#1{\allowbreak\mkern10mu({\operator@font mod}\,\,#1)}
\makeatother

\renewcommand{\O}{\ensuremath{\mathcal{O}}}
\renewcommand{\*}{\ensuremath{\cdot}}

\begin{document}

\selectlanguage{english}
\title{DD2440 Advanced Algorithms (fall 2009) \\ Project 2 -- Integer
factorization}
\author{Joel Pettersson \\ 880519-0637 \\ joelpet@kth.se \and Linus Wallgren \\
880213-0099  \\ linuswa@kth.se}
\date{\today}
\maketitle
\thispagestyle{empty}
\newpage
\setcounter{page}{1}

\selectlanguage{swedish}

\section{Inledning}

\subsection{Problembeskrivning}

Ett primtal är ett tal som endast är delbart med ett och sig själv. Alla tal som
inte är primtal går att dela upp i primtalsfaktorer. Det vi söker är varje sådan
primtalsfaktor till ett visst heltal, hädanefter refererat till som $n$ om inget
annat anges.




\section{Metod}

\subsection{Trial division}

Det mest triviala sättet att angripa problemet på är att bara testa om talet $n$ är delbart med en primtalsfaktor. Det är ett effektivt sätt att få bort små faktorer men det skalar inte speciellt bra då primtalsfaktorerna blir mer och mer sällsynta ju större faktorer vi söker.

I och med att algoritmen är såpass simpel finns det inte jättemycket att optimera. Det enda man kan hålla koll på är så man inte tittar på eventuella primtalsfaktorer större $\sqrt{n}$. Om vi låter talet $n$ beskrivas av två faktorer, $p$ och $q$, får vi $n = pq$. Ju större q är, desto mindre blir p och vice versa. Om fallet är att p är större än $\sqrt{n}$, kommer p vara mindre än $\sqrt{n}$, den största faktorn vi kan få blir således $\sqrt{n}$. 

\subsection{Pollards rho}

Vi betecknar den största gemensamma nämnaren med funktionen $gcd(x,y)$
\subsubsection{Grundläggande teori}

Låt $n = pq$, där $p$ och $q$ är okända faktorer till $n$. 
Vi söker då två tal, $a$ och $b$, sådana att $a = b (mod p)$.

$a=b(mod p)$
$a-b = 0 mod p$
$a - b = k*p$

Vi ser att $|a-b|$ är en multipel av $p$, även $n$ är en multipel av $p$ eftersom $p$ är en faktor till $n$. Den största gemensamma nämnaren mellan $|a-b|$ och $n$ är således en faktor till $n$, nämligen $p$. 

I dess grundläggande form utnytjar Pollards rho Floyds cykel-finnar-algoritm. Den går ut på att hålla koll på två tal som rör sig i olika hastighet i en cykel. När talen är lika har vi gått ett varv i cykeln.

Vi kommer leta därför att efter tal $a$ och $b$ sådana att $gcd(|a-b|, n) \notin {1, n}$. Om $gcd(|a-b|, n)$ visar sig vara 1 fortsätter vi leta med nya $a$ och $b$, ifall $gcd(|a-b|, n) = n$ innebär det att $a=b$ vilket, enligt Floyds cykel-finnar-algoritm, betyder att vi har fullföljt vår cykel och inte kommer hitta någon faktor.

Vi genererar de båda talen $a$ och $b$ med hjälp av en pseudo-slumpmässig funktion modulu $n$. Vi kallar denna funktion $f(x)$.

Anledningen till att vi kan applicera en Cykel-finnar algoritm är att vår pseudo-slumpmässiga funktion ger oss ett tal modulu N vilket innebär att vi endast kan få ett ändligt antal värden. Vi $a=f(a)$ och $b=f(f(b))$ i varje ny iteration av algoritmen. Vi gör detta för att hålla koll så att vi inte beräknar samma tal flera gånger, för när $a=b$ innebär det att vi gått ett varv i vår cykel och kommer således att börja om om vi skulle valt att fortsätta.

\subsubsection{Algoritmen}
Vi väljer funktionen $f(x) = x^2 + d (mod n)$ för att den visat sig vara effektiv vid experiment, mer specifikt är $d=1$ mycket effektiv. Det är viktigt att $d \notin {0, -2}$ då det innebär att vi  fastnar i en loop som aldrig kommer ge oss någon nyttig information. Vi börjar med ett slumpmässigt startvärde $X_0$ och sätter $a=b=X_0$. För varje iteration av algoritmen gör vi följande:

$a = f(a)$
$b = f(f(b))$

$b$ kommer alltså röra sig dubbelt så fort som $a$, vilket är nödvändigt för Floyds cykel-finnar algoritm.

För varje itteration beräknar vi också den största gemensamma delaren mellan $|a-b|$ och $n$. Om resultatet är $1$ har vi inte hittat någonting och gör ytterligare en itteration. Om resultatet blir $n$ innebär det att $a=b$ vilket betyder att vi inte kunde hitta någon faktor. I annat fall har vi hittat en faktor. Vi kan nu fortsätta genom att applicera pollards på de två faktorerna återstående faktorerna, tills vi finner primtal.

\begin{algorithmic}
    \STATE pollards rho($n$, $X_0$)
        \STATE $a \gets X_0 $
        \STATE $b \gets X_0 $

        \WHILE{$ factor = 1$}
            \STATE $a \gets f(a)$
            \STATE $b \gets f(f(b))$
            \STATE $factor \gets gcd(|a-b|, n)$
        \ENDWHILE

        \IF{$factor = n$}
            \STATE \COMMENT{Vi kunde inte hitta någon faktor}
            \RETURN $-1$ 
        \ELSIF{$factor > 1$}
            \RETURN $factor$
        \ENDIF
\end{algorithmic}


\subsubsection{Optimeringar}
\paragraph{Nya startväden}

Ifall $gcd(|a-b|, n) = n$ kan vi istället för att ge upp försöka med ett nytt startvärde, på det viset kan vi faktorisera mer eller mindre alla tal med hjälp av pollards $\rho$.

\begin{algorithmic}
    \STATE pollards rho($n$, $X_0$)
        \STATE $a \gets X_0 $
        \STATE $b \gets X_0 $

        \WHILE{$ factor = 1$}
            \STATE $a \gets f(a)$
            \STATE $b \gets f(f(b))$
            \STATE $factor \gets gcd(|a-b|, n)$
        \ENDWHILE

        \IF{$factor = n$}
            \STATE \COMMENT {Vi testar ett nytt startvärde}
            \RETURN pollards rho($n$, $X_0+1$) 
        \ELSIF{$factor > 1$}
            \RETURN $factor$
        \ENDIF
\end{algorithmic}

\paragraph{Flera gcds samtidigt}

Vi observerar att om den $gcd(x, y) > 1$, så är även $gcd(x\cdot k, b)>1$ för alla heltal $k$. Detta följer naturligt av definitionen på största gemensamma nämnaren.

Genom att utnytja detta fenomen kan vi räkna ut flera $|a-b|$ innan vi beräknar den största gemensamma nämnaren, vilket är en tidskrävande operation i förhållande till den tid som krävs för att applicera $f(x)$ på $a$ och $b$.

\begin{algorithmic}
    \STATE pollards rho($n$, $X_0$)
        \STATE $a \gets X_0 $
        \STATE $b \gets X_0 $

        \WHILE{$ factor = 1$}
            \FOR {$i = 0$ to $iterationer per gcd$}
                \STATE $a \gets f(a)$
                \STATE $b \gets f(f(b))$
                \STATE $factor \gets factor * |a-b|$
            \ENDFOR
            \STATE $factor \gets gcd(factor, n)$
        \ENDWHILE

        \IF{$factor = n$}
            \STATE \COMMENT {Vi testar ett nytt startvärde}
            \RETURN pollards rho($n$, $X_0+1$) 
        \ELSIF{$factor > 1$}
            \RETURN $factor$
        \ENDIF
\end{algorithmic}

\paragraph{Brent}

Tanken bakom optimeringen som Brent och Pollard kom fram till är att endast göra ett funktionsanrop till $f(x)$ i varje iteration, istället för tre. Detta sker genom att vi använder Brent's metod för att hitta cykler istället för Floyd's. 

Floyd's algoritm för att hitta cykler går ut på att låta talet $b$ röra sig dubbelt så fort som $a$. Brents algoritm söker istället efter den minsta tvåpotens som är större än längden på cykeln.
\begin{algorithmic}
    \STATE pollards rho($n$, $X_0$)
        \STATE $power \gets 1$
        \STATE $iterations \gets 1$

        \WHILE{$ factor = 1$}
            \FOR {$i = 0$ to $iterationer per gcd$}
                \IF {$power = iterations$}
                    \STATE $a \gets b$
                    \STATE $power \gets power *2$
                    \STATE $iterations \gets 0$
                \ENDIF 
                \STATE $b \gets f(b)$

                \STATE $iterations \gets iterations + 1$

                \STATE $factor \gets factor * |a-b|$
            
            \ENDFOR


            \STATE $factor = gcd(factor, n)$
        \ENDWHILE

        \IF{$factor = n$}
            \STATE \COMMENT {Vi testar ett nytt startvärde}
            \RETURN pollards rho($n$, $X_0+1$) 
        \ELSIF{$factor > 1$}
            \RETURN $factor$
        \ENDIF
\end{algorithmic}


\subsection{Kvadratiska sållet}

Den grundläggande tanken bakom kvadratiska såll-metoden är relativt enkel. Målet
är att finna två tal $x, y \in \mathbb{Z}$ sådana att
\begin{align*}
    x^2 \equiv y^2 \imod{n}, \ \text{ men } x \not\equiv \pm y \imod{n}.
\end{align*}

Då råder enligt konjugatregeln ekvivalensen
\begin{align*}
    n \mid (x^2 - y^2) \Leftrightarrow n \mid (x+y)(x-y).
\end{align*}

Vidare gäller att $n \nmid (x+y)$ och $n \nmid (x-y)$, ty $x \not\equiv \pm y
\imod{n}$. 

Därmed kommer $d = \text{gcd}\left( n, x \pm y \right)$ att vara faktorer  $n$
-- men dock eventuellt triviala sådana. Sannolikheten att vi får triviala
lösningar är $50 \%$ om $n$ består av endast två primtal och i annat fall lägre
chans. Således kan vi behöva upprepa algoritmen tills icke-triviala faktorer
hittas.

Nu återstår bara frågan \emph{hur hittar vi effektivt talen $x$ och $y$}?

\subsubsection{Fermats algoritm}

Den naiva ansatsen vore här att låta $x$ vandra från $\sqrt{n}$ och uppåt i
förhoppning om att finna ett $x$ som uppfyller just $x^2 \equiv y^2 \imod{n}$
för något $y \in \mathbb{Z}$. Detta påminner väldigt mycket om Fermats
faktoriseringsalgoritm som letar efter tal som uppfyller liknande villkor.

Problemet är att det i praktiken tar alldeles för lång tid att hitta sådana tal
på det viset, eftersom de är relativt få. Detta fick vi även bekräftat av
resultatet 2 poäng på KATTIS för vår implementation av algoritmen. En förbättrad
strategi presenterades av Dixon och beskrivs i nästa delsektion.


\subsubsection{Dixons metod}

Dixon valde att släppa på kravet på jämna kvadrater och nöjde sig med att finna
$x$ och $y$ så som beskrivet ovan fast där $y$ bara behöver kunna faktoriseras
i små primtal. Det vill säga att $y$ ska kunna skrivas som $y =
p_1^{a_1}p_2^{a_2} \cdots p_k^{a_k}$ för små primtal $p_i$, $i = 1, 2, \dots k$.

Givet en mängd sådana tal $y$ är det möjligt att genom linjär algebra, speciellt
genom Gauss-eliminering modulo 2, finna delmängder vars produkter av de ingående
elementen bildar en jämn kvadrat. Detta tack vare observationen att två tal
$y_i$ och $y_j$ (utan förlust av generalitet) kan skrivas som en jämn kvadrat om
och endast om summan av exponenterna för deras respektive primtalsfaktorer är
jämn.

Då har vi funnit ett talpar $(x, y)$ som vi sökte, vilet genom Euklides algoritm
förhoppningsvis ger icke-triviala faktorer.

Denna ansats ökar chanserna att ett sådant talpar ska dyka upp. För att
illustrera detta kan nämnas att antalet jämna kvadrater som är mindre än $84923$
är 292 stycken, medan det finns 662 stycken tal som låter sig faktoriseras av
endast 2, 3, 5 och 7 samt 4767 tal vars primtalsfaktorer alla är mindre än 30.
Ändå tar det orimligt lång tid för stora $n$ att så urskiljningslöst bara pröva
$x$. Lyckligtvis presenterade Carl Pomerance en effektiv metod för att sålla
bort ointressanta tal $x$, kallad \emph{Quadratic Sieve} (`kvadratiska sållet').


\subsubsection{Kvadratiska sållet}

Betrakta polynomet 
\begin{align*}
    f(x) = (x + \left\lfloor \sqrt{n} \right\rfloor)^2 - n
\end{align*}
och notera att
\begin{align*}
    (x + \lfloor \sqrt{n} \rfloor)^2 \equiv f(x) \imod{n}.
\end{align*}

Antag nu att vi lyckas finna heltal $x_i, i = 1, 2, \dots, k$ så att
$f(x_1)f(x_2)\cdots f(x_k)$ kan skrivas som en jämn kvadrat $y^2$ för något
heltal $y$. Låt 
\begin{align*}
    x = (x_1 + \lfloor \sqrt{n} \rfloor) (x_2 + \lfloor \sqrt{n} \rfloor)\cdots
    (x_k + \lfloor \sqrt{n} \rfloor).
\end{align*}
Då har vi en lösning till $x^2 \equiv y^2 \imod{n}$.

Om $y$ ska kunna skrivas som en kvadrat vill vi skriva de ingående faktorerna
$f(x_i)$ som produkter av en gemensam uppsättning primtal, kallad 
\emph{faktorbasen} för talet $n$. Av den anledningen vill vi inte ha $f(x_i)$
som delas av stora primtal eftersom det i sådana fall skulle krävas andra
$f(x_j)$ som delas av samma stora primtal. 






\section{Resultat}

Första versionen av Pollards, ensam, gav oss 28 poäng på KATTIS. Den enda optimeringen som gjordes var att dividera med 2 om talet var jämnt.

I andra revisionen av Pollards rho ändrade vi startvärdet för de två talen till 3, vilket gav oss en extra poäng samt en hel del extra tid, men tiden över kunde vi angripa större tal. I den här revisionen angrep Pollards rho alla tal mindre än 87 bitar, vilket resulterade i 31 poäng.

Genom att implementera trial division på de 256 första primtalen kunde vi ta hem ytterligare poäng, KATTIS gav oss vid den här tidpunkten 38 poäng.

Nästa steg var att testa med nya startvärden för de två talen i Pollards rho om vi misslyckades att finna en faktor. Detta innebär att vår implementation av Pollards rho lyckas faktorisera alla tal vi får från KATTIS som är mindre än 87 bitar.

Genom att beräkna den största gemensamma delaren endast var 13e iteration lyckades vi minska körtiden med mer än 10 sekunder. Detta gav oss möjligheten att testa tal mindre än 88 bitar, vilket resulterade i 39 poäng.

Den sista optimeringen av Pollards rho vi gjorde var att byta cykel-finnar-algoritmen från Floyds till Brents, det gav ungefär 5 sekunders förbättring och möjligheten att angripa alla tal mindre än 89 bitar. Tråkigt nog gav det inte oss några extra poäng så vi gick tillbaka till 88 bitar igen. Med tiden som blev över gick vi från att testa med de 150 första primtalen till att testa de 10000 första primtalen i trial divison, vilket gav oss den slutgiltiga poängen, 40.






\end{document}
